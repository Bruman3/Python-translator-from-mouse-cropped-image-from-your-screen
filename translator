import numpy as np
from PIL import Image
import cv2
import pyautogui
import pytesseract
from langdetect import detect
from googletrans import Translator
#Made by Bruman3

pytesseract.pytesseract.tesseract_cmd = r"C:\Users\Hellen\Desktop\william's stuff\pytess\tesseract"
translator = Translator()

refPt = []
cropping = False


def click_and_crop(event, x, y, flags, param):
    # grab references to the global variables
    global refPt, cropping
    # if the left mouse button was clicked, record the starting
    # (x, y) coordinates and indicate that cropping is being
    # performed
    if event == cv2.EVENT_LBUTTONDOWN:
        refPt = [(x, y)]
        cropping = True
    # check to see if the left mouse button was released
    elif event == cv2.EVENT_LBUTTONUP:
        # record the ending (x, y) coordinates and indicate that
        # the cropping operation is finished
        refPt.append((x, y))
        cropping = False
        # draw a rectangle around the region of interest
        cv2.rectangle(image, refPt[0], refPt[1], (0, 255, 0), 2)
        cv2.imshow("image", image)


img = pyautogui.screenshot()
image = np.array(img)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image = cv2.resize(image, (1300, 800))

clone = image.copy()
cv2.namedWindow("image")
cv2.setMouseCallback("image", click_and_crop)

while True:
    cv2.imshow("image", image)
    key = cv2.waitKey(1) & 0xFF
    # if the 'r' key is pressed, reset the cropping region
    if key == ord("r"):
        image = clone.copy()
    # if the 'c' key is pressed, break from the loop
    elif key == ord("c"):
        break

if len(refPt) == 2:
    cv2.destroyAllWindows()
    roi = clone[refPt[0][1]:refPt[1][1], refPt[0][0]:refPt[1][0]]
    cv2.imshow("ROI", roi)

# crop image with mouse https://pyimagesearch.com/2015/03/09/capturing-mouse-click-events-with-python-and-opencv/

cv2.imwrite('cropimage.jpg', roi)
img = Image.open(r'C:\Users\Hellen\PycharmProjects\stockthings\cropimage.jpg')
text = pytesseract.image_to_string(img)
# Displaying the extracted text
print('Image to text:')
print(text[:-1])
#image to text

print(''
      '')
print('Detecting language')
language = detect(text)
print(f'language detected: {language}')
print(''
      '')
#detects language

while 1:
    if language == 'en':
        print('Since text is english no further translation will be needed')
        break
    else:
        print(''
              '')
        translated = translator.translate(text)
        print(f"{translated.origin} ({translated.src}) --> {translated.text} ({translated.dest})")
        break
#translates

cv2.waitKey(0)
